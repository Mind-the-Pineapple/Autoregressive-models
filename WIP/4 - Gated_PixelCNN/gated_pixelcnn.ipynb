{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gated_pixelcnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1uZnxh4Xz9Z",
        "colab": {}
      },
      "source": [
        "import random as rn\n",
        "import time\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NN6vJl7eVnZ4",
        "colab": {}
      },
      "source": [
        "# Defining random seeds\n",
        "random_seed = 42\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "rn.seed(random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8BnkhgCjVpJu",
        "colab": {}
      },
      "source": [
        "# Loading data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "height = 28\n",
        "width = 28\n",
        "n_channel = 1\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], height, width, n_channel)\n",
        "x_test = x_test.reshape(x_test.shape[0], height, width, n_channel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ne-qY7JVZaB",
        "colab": {}
      },
      "source": [
        "def quantise(images, q_levels):\n",
        "    \"\"\"Quantise image into q levels\"\"\"\n",
        "    return (np.digitize(images, np.arange(q_levels) / q_levels) - 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3QVhnMymVrzc",
        "colab": {}
      },
      "source": [
        "# Quantise the input data in q levels\n",
        "q_levels = 2\n",
        "x_train_quantised = quantise(x_train, q_levels)\n",
        "x_test_quantised = quantise(x_test, q_levels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZObIXqzNGwmo",
        "colab": {}
      },
      "source": [
        "# Creating input stream using tf.data API\n",
        "batch_size = 128\n",
        "train_buf = 60000\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_quantised / (q_levels - 1),\n",
        "                                                    x_train_quantised.astype('int32')))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_quantised / (q_levels - 1),\n",
        "                                                   x_test_quantised.astype('int32')))\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "75VTDkK8VZLA",
        "colab": {}
      },
      "source": [
        "class MaskedConv2D(keras.layers.Layer):\n",
        "    \"\"\"Convolutional layers with masks for Gated PixelCNN.\n",
        "\n",
        "    Masked convolutional layers used to implement Vertical and Horizontal\n",
        "    stacks of the Gated PixelCNN.\n",
        "\n",
        "    Note: This implementation is different from the normal PixelCNN.\n",
        "\n",
        "    Arguments:\n",
        "    mask_type: one of `\"V\"`, `\"A\"` or `\"B\".`\n",
        "    filters: Integer, the dimensionality of the output space\n",
        "        (i.e. the number of output filters in the convolution).\n",
        "    kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
        "        height and width of the 2D convolution window.\n",
        "        Can be a single integer to specify the same value for\n",
        "        all spatial dimensions.\n",
        "    strides: An integer or tuple/list of 2 integers,\n",
        "        specifying the strides of the convolution along the height and width.\n",
        "        Can be a single integer to specify the same value for\n",
        "        all spatial dimensions.\n",
        "        Specifying any stride value != 1 is incompatible with specifying\n",
        "        any `dilation_rate` value != 1.\n",
        "    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
        "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "    bias_initializer: Initializer for the bias vector.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 mask_type,\n",
        "                 filters,\n",
        "                 kernel_size,\n",
        "                 strides=1,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros'):\n",
        "        super(MaskedConv2D, self).__init__()\n",
        "\n",
        "        assert mask_type in {'A', 'B', 'V'}\n",
        "        self.mask_type = mask_type\n",
        "\n",
        "        self.filters = filters\n",
        "\n",
        "        if isinstance(kernel_size, int):\n",
        "            kernel_size = (kernel_size, kernel_size)\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        self.strides = strides\n",
        "        self.padding = padding.upper()\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        kernel_h, kernel_w = self.kernel_size\n",
        "\n",
        "        self.kernel = self.add_weight('kernel',\n",
        "                                      shape=(kernel_h,\n",
        "                                             kernel_w,\n",
        "                                             int(input_shape[-1]),\n",
        "                                             self.filters),\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      trainable=True)\n",
        "\n",
        "        self.bias = self.add_weight('bias',\n",
        "                                    shape=(self.filters,),\n",
        "                                    initializer=self.bias_initializer,\n",
        "                                    trainable=True)\n",
        "\n",
        "        mask = np.ones(self.kernel.shape, dtype=np.float32)\n",
        "\n",
        "        if kernel_h % 2 != 0: \n",
        "            center_h = kernel_h // 2\n",
        "        else:\n",
        "            center_h = (kernel_h - 1) // 2\n",
        "\n",
        "        if kernel_w % 2 != 0: \n",
        "            center_w = kernel_w // 2\n",
        "        else:\n",
        "            center_w = (kernel_w - 1) // 2\n",
        "\n",
        "        if self.mask_type == 'V':\n",
        "            mask[center_h + 1:, :, :, :] = 0.\n",
        "        else:\n",
        "            mask[:center_h, :, :] = 0.\n",
        "            mask[center_h, center_w + (self.mask_type == 'B'):, :, :] = 0.\n",
        "            mask[center_h + 1:, :, :] = 0.          \n",
        "\n",
        "        self.mask = tf.constant(mask, dtype=tf.float32, name='mask')\n",
        "\n",
        "    def call(self, input):\n",
        "        masked_kernel = tf.math.multiply(self.mask, self.kernel)\n",
        "        x = nn.conv2d(input,\n",
        "                      masked_kernel,\n",
        "                      strides=[1, self.strides, self.strides, 1],\n",
        "                      padding=self.padding)\n",
        "        x = nn.bias_add(x, self.bias)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PTUN4s52Nu3w",
        "colab": {}
      },
      "source": [
        "class GatedBlock(tf.keras.Model):\n",
        "    \"\"\" Gated block of the Gated PixelCNN.\"\"\"\n",
        "\n",
        "    def __init__(self, mask_type, filters, kernel_size):\n",
        "        super(GatedBlock, self).__init__(name='')\n",
        "\n",
        "        self.mask_type = mask_type\n",
        "        self.vertical_conv = MaskedConv2D(mask_type='V',\n",
        "                                          filters=2 * filters,\n",
        "                                          kernel_size=kernel_size)\n",
        "        \n",
        "        self.horizontal_conv = MaskedConv2D(mask_type=mask_type,\n",
        "                                            filters=2 * filters,\n",
        "                                            kernel_size=kernel_size)\n",
        "\n",
        "        self.padding = keras.layers.ZeroPadding2D(padding=((1,0),0))\n",
        "        self.cropping = keras.layers.Cropping2D(cropping=((0, 1), 0))\n",
        "\n",
        "        self.v_to_h_conv = keras.layers.Conv2D(filters=2 * filters, kernel_size=1)\n",
        "\n",
        "        self.horizontal_output = keras.layers.Conv2D(filters=filters, kernel_size=1)\n",
        "\n",
        "    def _gate(self, x):\n",
        "        tanh_preactivation, sigmoid_preactivation = tf.split(x, 2, axis=-1)\n",
        "        return tf.nn.tanh(tanh_preactivation) * tf.nn.sigmoid(sigmoid_preactivation)\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        v = input_tensor[0]\n",
        "        h = input_tensor[1]\n",
        "\n",
        "        vertical_preactivation = self.vertical_conv(v)  # NxN\n",
        "\n",
        "        # Shifting feature map down to ensure causality\n",
        "        v_to_h = self.padding(vertical_preactivation)\n",
        "        v_to_h = self.cropping(v_to_h)\n",
        "        v_to_h = self.v_to_h_conv(v_to_h)  # 1x1\n",
        "\n",
        "        horizontal_preactivation = self.horizontal_conv(h)  # 1xN\n",
        "        \n",
        "        v_out = self._gate(vertical_preactivation)\n",
        "\n",
        "        horizontal_preactivation = horizontal_preactivation + v_to_h\n",
        "        h_activated = self._gate(horizontal_preactivation)\n",
        "        h_activated = self.horizontal_output(h_activated)\n",
        "\n",
        "        if self.mask_type == 'A':\n",
        "            h_out = h_activated\n",
        "        elif self.mask_type == 'B':\n",
        "            h_out = h + h_activated\n",
        "\n",
        "        return v_out, h_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WB57YufrVxn2",
        "colab": {}
      },
      "source": [
        "# Create Gated PixelCNN model\n",
        "inputs = keras.layers.Input(shape=(height, width, n_channel))\n",
        "v, h = GatedBlock(mask_type='A', filters=64, kernel_size=3)([inputs, inputs])\n",
        "\n",
        "for i in range(7):\n",
        "    v, h = GatedBlock(mask_type='B', filters=64, kernel_size=3)([v, h])\n",
        "\n",
        "x = keras.layers.Activation(activation='relu')(h)\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=1, strides=1)(x)\n",
        "\n",
        "x = keras.layers.Activation(activation='relu')(x)\n",
        "x = keras.layers.Conv2D(filters=q_levels, kernel_size=1, strides=1)(x)\n",
        "\n",
        "gated_pixelcnn = tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_LnzHUaqV77d",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer and loss function\n",
        "lr_decay = 0.999995\n",
        "learning_rate = 1e-3\n",
        "optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "compute_loss = keras.losses.CategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CsAgEKVzLCJD",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(batch_x, batch_y):\n",
        "    with tf.GradientTape() as ae_tape:\n",
        "        logits = gated_pixelcnn(batch_x, training=True)\n",
        "\n",
        "        loss = compute_loss(tf.squeeze(tf.one_hot(batch_y, q_levels)), logits)\n",
        "\n",
        "    gradients = ae_tape.gradient(loss, gated_pixelcnn.trainable_variables)\n",
        "    gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
        "    optimizer.apply_gradients(zip(gradients, gated_pixelcnn.trainable_variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NoEPrfwQNM-s",
        "outputId": "52dae9be-4f84-4b91-c5ba-e2369259478e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "# Training loop\n",
        "n_epochs = 100\n",
        "n_iter = int(np.ceil(x_train_quantised.shape[0] / batch_size))\n",
        "for epoch in range(n_epochs):\n",
        "    progbar = Progbar(n_iter)\n",
        "    print('Epoch {:}/{:}'.format(epoch + 1, n_epochs))\n",
        "\n",
        "    for i_iter, (batch_x, batch_y) in enumerate(train_dataset):\n",
        "        optimizer.lr = optimizer.lr * lr_decay\n",
        "        loss = train_step(batch_x, batch_y)\n",
        "\n",
        "        progbar.add(1, values=[('loss', loss)])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 176s 376ms/step - loss: 0.1096\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 171s 366ms/step - loss: 0.0892\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 171s 365ms/step - loss: 0.0864\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 171s 365ms/step - loss: 0.0848\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 171s 365ms/step - loss: 0.0837\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 171s 365ms/step - loss: 0.0829\n",
            "Epoch 7/100\n",
            " 92/469 [====>.........................] - ETA: 2:18 - loss: 0.0824"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-98c1fb2b10eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, n, values)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seen_so_far\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    488\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_base\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    913\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1199\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   6112\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6113\u001b[0;31m         x, y)\n\u001b[0m\u001b[1;32m   6114\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6115\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ue0vZbitSNmz",
        "outputId": "b4be6fad-6f16-4380-8dbd-2e01bc3e1af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Test set performance\n",
        "test_loss = []\n",
        "for batch_x, batch_y in test_dataset:\n",
        "    logits = gated_pixelcnn(batch_x, training=False)\n",
        "\n",
        "    # Calculate cross-entropy (= negative log-likelihood)\n",
        "    loss = compute_loss(tf.one_hot(batch_y, q_levels), logits)\n",
        "\n",
        "    test_loss.append(loss)\n",
        "print('nll : {:} nats'.format(np.array(test_loss).mean()))\n",
        "print('bits/dim : {:}'.format(np.array(test_loss).mean() / np.log(2)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nll : 0.08227105438709259 nats\n",
            "bits/dim : 0.11869204217296468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Ia9VXYySkuW",
        "outputId": "924010f4-0dcb-4a82-bd1d-75c6091cadc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "# Generating new images\n",
        "samples = np.zeros((100, height, width, n_channel), dtype='float32')\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        logits = gated_pixelcnn(samples)\n",
        "        next_sample = tf.random.categorical(logits[:, i, j, :], 1)\n",
        "        samples[:, i, j, 0] = (next_sample.numpy() / (q_levels - 1))[:, 0]\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(100):\n",
        "    ax = fig.add_subplot(10, 10, i + 1)\n",
        "    ax.matshow(samples[i, :, :, 0], cmap=matplotlib.cm.binary)\n",
        "    plt.xticks(np.array([]))\n",
        "    plt.yticks(np.array([]))\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAI0CAYAAAAdqSPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 100 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KBuWx-FtSouR",
        "outputId": "85fb1988-aeea-4695-f5e3-d5a57d28bed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Filling occluded images\n",
        "occlude_start_row = 14\n",
        "num_generated_images = 10\n",
        "samples = np.copy(x_test_quantised[0:num_generated_images, :, :, :])\n",
        "samples = samples / (q_levels - 1)\n",
        "samples[:, occlude_start_row:, :, :] = 0\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.matshow(samples[i, :, :, 0], cmap=matplotlib.cm.binary)\n",
        "    plt.xticks(np.array([]))\n",
        "    plt.yticks(np.array([]))\n",
        "\n",
        "for i in range(occlude_start_row, height):\n",
        "    for j in range(width):\n",
        "        logits = gated_pixelcnn(samples)\n",
        "        next_sample = tf.random.categorical(logits[:, i, j, :], 1)\n",
        "        samples[:, i, j, 0] = (next_sample.numpy() / (q_levels - 1))[:, 0]\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.matshow(samples[i, :, :, 0], cmap=matplotlib.cm.binary)\n",
        "    plt.xticks(np.array([]))\n",
        "    plt.yticks(np.array([]))\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAABECAYAAABu1lQcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAADy0lEQVR4nO3cQVLkOBAF0PTEHIFeTx2C+58A7kCv\nhztoFkwHBOFy2WW7UCrfW3Y4OpSWbL5Shqm1FgAAVfz10wMAAHgk4QcAKEX4AQBKEX4AgFKEHwCg\nFOEHAChF+AEAShF+AIBShB8AoJS/t1z89PTULpfLSUM519vbW7y/v09L12SuLyLi9fX1vbX2a+ma\nzDWumcMINfbOs/ghc43W6afRa8xcX8T1Z3FT+LlcLvHy8nLcqB7o+fn55jWZ64uImKbp961rMte4\nZg4j1Ng7z+KHzDVap59GrzFzfRHXn0XHXgBAKcIPAFDKpmMvtpum+ePU1tqDRwIAROj8AADF6Pwc\n5FqH59b1FTpAo9Q6N8fZawLGNE2T99MCnR8AoBSdnwNs7fpAT0bpzO2V8T58f/dkGjvb3XvC8If1\n8Un4OcnSIvu6IDO+cNcaKRSOVMtRvt6TzOv3+9xmeCbPWI9Z5jPLOPfyzjmXYy8AoJRTOz8VPxDd\nWt/o9yO7W7uvDF2Ca/buLFtrdqc/4Oj3apajEWttbI/OCzo/AEApp3R+lhL6kem9lx3K2nFU3bn0\nMk9b+LCwhuzd6UxjvdeanydZ78O9489a7x9r369L1+29B6eEn7Uf++6VfeGPLGvQO2rcPf+NjaOC\nWtY5zuqMD317/nh4y/rq+Xm75lZ92epZ0uO7wrEXAFDKw3/VfW+a7Xmnck321jrzvs5hjzubORmf\nnzNkma+IXGP9SVlOAqrM59o65+br+1zO/V97u306PwBAKf7I4cmqpPwR7NmpzO1QsuxEtxp1TY82\nT3Myd6GXOgRz/9ZbXZnv/dHu+cD76PeOzg8AUEqazk+2bxXO/BW9nmWbp7XW1tJrB+iseRlpjjPZ\n8ht72Tt1o66xUes6osO19K3PUboPP9kf3K9GXewjM2efRnoWM1nzg+Deuel1ffe2edjLs/Ohp7/z\n59gLACil+85P1rSfddx7Za575OOgI8bTW017ZKwl45jvtfWYuXdZxnmEpVp7ug86PwBAKcIPAFCK\n8AMAlCL8AAClCD8AQCnCDwBQivADAJQi/AAApQg/AEApwg8AUIrwAwCUIvwAAKUIPwBAKcIPAFCK\n8AMAlCL8AAClCD8AQCnCDwBQivADAJQi/AAApQg/AEApwg8AUIrwAwCUMrXW1l88Tf9GxO/zhnOq\nf1prv5YuSF5fxPg13qwvQo0JjL5OI8av0Tr93+g1Jq8v4kqNm8IPAEB2jr0AgFKEHwCgFOEHAChF\n+AEAShF+AIBShB8AoBThBwAoRfgBAEoRfgCAUv4Dzge+SeXbn58AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAABECAYAAABu1lQcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAFPklEQVR4nO3dS27jOBAAUGowR0ivx4fI/U+Q3KF7\nPbmDZpEJbBj62qLMYr23DISAJVJMsUgpwziOBQAgi79e3QAAgDNJfgCAVCQ/AEAqkh8AIBXJDwCQ\niuQHAEhF8gMApCL5AQBSkfwAAKn8vefit7e38XK5VGpKXb9//y5fX1/D0jWR4yullM/Pz69xHH8t\nXRM5xi19WIoYW+dZ/BY5RuP0qvcYI8dXyvyzuCv5uVwu5ePj47hWnej9/X31msjxlVLKMAx/1q6J\nHOOWPixFjK3zLH6LHKNxetV7jJHjK2X+WbTtBQCkIvkBAFLZte3FfsMwvZ06juPJLQEASlH5AQCS\nUfk5yFyFZ+36DBWgXmKd6uPoMQF9GobB/LRA5QcASEXl5wB7qz7Qkl4qc8+KeB/u555IbWe/R3cY\nfhgfV5KfSpYG2e2AjDjhbtVTUthTLEe5vSeRx+9930Z4JmuMxyj9GaWdzzLn1GXbCwBIpWrlJ+MB\n0b3x9X4/oltbfUWoEsx5dmU5jqPV6QscPa9G2Rox1vp2dr6g8gMApFKl8rOUoR+ZvbeyQtnajqwr\nl1b6aQ8HC3OIXp2O1NZHbfl7EvU+PNr+qPH+2Dq/Ll337D2okvxsPez7rOgDv2dRE72j2t3yNzaO\nStSi9nFUNQ76tnx4eM/4avl5m7MWX7R4lrQ4V9j2AgBSOf1V92ez2ZZXKnOil9aZdtuHLa5spkR8\nfmqI0l+lxGrrK0XZCcjSn1vjnOqv+76c+l3PVvtUfgCAVHzksLIsWX4PnlmpTK1QoqxE9+p1TPfW\nT1MiV6GXKgRTP2strsj3/miPHPA+et5R+QEAUglT+Yl2VqHmK3oti9ZPW22NpdUKUK1+6amPI9nz\nxl70Sl2vY6zXuI6ocC2d9TlK88lP9Af3Vq+DvWf67KqnZzGSLX8IHu2bVsd3a4uHZ3l2vrX0nT/b\nXgBAKs1WfuYyxMjZf3atH/hrqS01Zf4adeQV+NYDv3t/B+fK2ActPncqPwBAKk1Ufno/HNxDDGuW\nXjnl9ZY+yLhUkev92SwldhyR275k6tXmHs7+ZFDrsPLR/d5E8jMl6gDP+gd/asBH7cPe3feLxJVI\nMv1PrMha/wK+bS8AIJWqlZ+pMmWGMjrtq1Whav1Q95TW23eUFlefzDvjWy9nud3Gm5p7evtUwb0t\n7Ty7n1V+AIBUTjnzk6na09Nq5RG38Wc6oJi1v6EVrc8zS19/f1SmOfZoKj8AQCqnv+2VJUPNEue9\niBWQZ1ZPmaqa8Apb3k6M5Ih5Ifo9uPWqWKomPyb/fKJs+y19R+TZ3wvU0/or1MRg2wsASKXZjxxC\nbUdWqVR8AK7WjgTsmXdrzK8qPwBAKio/VNf665h7/1t2q3HwmC0rUH0O22x5nlo4qyX5oYq9Zc3W\n+GN3NdePvd+j3uOLLPLc0quafTIMw+HPo20vACAVlZ8Xybqapm1W1J5B2uT/Bh5L5QcASEXlp7K9\nK+kae5uv0kscme09DN6ytXNovY7XnuaUUuKOv0dFrPhEoPIDAKSi8nOQPa/Lrl3b+qvh5HY7jqON\n0Wjt3Wtubrn/eW/3obd4Sumj4tNypVXyU8lSx651+s+AkQRxtvsEfSrBMS7bs/SHspdtoh6Sga0i\nxrp3i/zV84htLwAglWFP1jUMw7+llD/1mlPVP+M4/lq6IHh8pfQf42p8pYgxgN7HaSn9x2ic/q/3\nGIPHV8pMjLuSHwCA6Gx7AQCpSH4AgFQkPwBAKpIfACAVyQ8AkIrkBwBIRfIDAKQi+QEAUpH8AACp\n/AcUCbSNo+kQgwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}