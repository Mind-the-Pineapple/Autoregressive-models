{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1uZnxh4Xz9Z"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import random as rn\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NN6vJl7eVnZ4"
   },
   "outputs": [],
   "source": [
    "# Defining random seeds\n",
    "random_seed = 42\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "rn.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BnkhgCjVpJu"
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "height = 28\n",
    "width = 28\n",
    "n_channel = 1\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], height, width, n_channel)\n",
    "x_test = x_test.reshape(x_test.shape[0], height, width, n_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ne-qY7JVZaB"
   },
   "outputs": [],
   "source": [
    "def quantise(images, q_levels):\n",
    "    \"\"\"Quantise image into q levels\"\"\"\n",
    "    return (np.digitize(images, np.arange(q_levels) / q_levels) - 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QVhnMymVrzc"
   },
   "outputs": [],
   "source": [
    "# Quantise the input data in q levels\n",
    "q_levels = 2\n",
    "x_train_quantised = quantise(x_train, q_levels)\n",
    "x_test_quantised = quantise(x_test, q_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZObIXqzNGwmo"
   },
   "outputs": [],
   "source": [
    "# Creating input stream using tf.data API\n",
    "batch_size = 192\n",
    "train_buf = 10000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_quantised / (q_levels - 1),\n",
    "                                                    x_train_quantised.astype('int32')))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_quantised / (q_levels - 1),\n",
    "                                                   x_test_quantised.astype('int32')))\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "75VTDkK8VZLA"
   },
   "outputs": [],
   "source": [
    "class MaskedConv2D(keras.layers.Layer):\n",
    "    \"\"\"Convolutional layers with masks for Gated PixelCNN.\n",
    "\n",
    "    Masked convolutional layers used to implement Vertical and Horizontal\n",
    "    stacks of the Gated PixelCNN.\n",
    "\n",
    "    Note: This implementation is different from the normal PixelCNN.\n",
    "\n",
    "    Arguments:\n",
    "    mask_type: one of `\"V\"`, `\"A\"` or `\"B\".`\n",
    "    filters: Integer, the dimensionality of the output space\n",
    "        (i.e. the number of output filters in the convolution).\n",
    "    kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
    "        height and width of the 2D convolution window.\n",
    "        Can be a single integer to specify the same value for\n",
    "        all spatial dimensions.\n",
    "    strides: An integer or tuple/list of 2 integers,\n",
    "        specifying the strides of the convolution along the height and width.\n",
    "        Can be a single integer to specify the same value for\n",
    "        all spatial dimensions.\n",
    "        Specifying any stride value != 1 is incompatible with specifying\n",
    "        any `dilation_rate` value != 1.\n",
    "    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
    "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
    "    bias_initializer: Initializer for the bias vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 mask_type,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros'):\n",
    "        super(MaskedConv2D, self).__init__()\n",
    "\n",
    "        assert mask_type in {'A', 'B', 'V'}\n",
    "        self.mask_type = mask_type\n",
    "\n",
    "        self.filters = filters\n",
    "\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.strides = strides\n",
    "        self.padding = padding.upper()\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        kernel_h, kernel_w = self.kernel_size\n",
    "\n",
    "        self.kernel = self.add_weight('kernel',\n",
    "                                      shape=(kernel_h,\n",
    "                                             kernel_w,\n",
    "                                             int(input_shape[-1]),\n",
    "                                             self.filters),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      trainable=True)\n",
    "\n",
    "        self.bias = self.add_weight('bias',\n",
    "                                    shape=(self.filters,),\n",
    "                                    initializer=self.bias_initializer,\n",
    "                                    trainable=True)\n",
    "\n",
    "        mask = np.ones(self.kernel.shape, dtype=np.float32)\n",
    "\n",
    "        if kernel_h % 2 != 0: \n",
    "            center_h = kernel_h // 2\n",
    "        else:\n",
    "            center_h = (kernel_h - 1) // 2\n",
    "\n",
    "        if kernel_w % 2 != 0: \n",
    "            center_w = kernel_w // 2\n",
    "        else:\n",
    "            center_w = (kernel_w - 1) // 2\n",
    "\n",
    "        if self.mask_type == 'V':\n",
    "            mask[center_h + 1:, :, :, :] = 0.\n",
    "        else:\n",
    "            mask[:center_h, :, :] = 0.\n",
    "            mask[center_h, center_w + (self.mask_type == 'B'):, :, :] = 0.\n",
    "            mask[center_h + 1:, :, :] = 0.          \n",
    "\n",
    "        self.mask = tf.constant(mask, dtype=tf.float32, name='mask')\n",
    "\n",
    "    def call(self, input):\n",
    "        masked_kernel = tf.math.multiply(self.mask, self.kernel)\n",
    "        x = nn.conv2d(input,\n",
    "                      masked_kernel,\n",
    "                      strides=[1, self.strides, self.strides, 1],\n",
    "                      padding=self.padding)\n",
    "        x = nn.bias_add(x, self.bias)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTUN4s52Nu3w"
   },
   "outputs": [],
   "source": [
    "class GatedBlock(tf.keras.Model):\n",
    "    \"\"\" Gated block of the Gated PixelCNN.\"\"\"\n",
    "\n",
    "    def __init__(self, mask_type, filters, kernel_size):\n",
    "        super(GatedBlock, self).__init__(name='')\n",
    "\n",
    "        self.mask_type = mask_type\n",
    "        self.vertical_conv = MaskedConv2D(mask_type='V',\n",
    "                                          filters=2 * filters,\n",
    "                                          kernel_size=kernel_size)\n",
    "        \n",
    "        self.horizontal_conv = MaskedConv2D(mask_type=mask_type,\n",
    "                                            filters=2 * filters,\n",
    "                                            kernel_size=kernel_size)\n",
    "\n",
    "        self.padding = keras.layers.ZeroPadding2D(padding=((1,0),0))\n",
    "        self.cropping = keras.layers.Cropping2D(cropping=((0, 1), 0))\n",
    "\n",
    "        self.v_to_h_conv = keras.layers.Conv2D(filters=2 * filters, kernel_size=1)\n",
    "\n",
    "        self.horizontal_output = keras.layers.Conv2D(filters=filters, kernel_size=1)\n",
    "\n",
    "    def _gate(self, x):\n",
    "        tanh_preactivation, sigmoid_preactivation = tf.split(x, 2, axis=-1)\n",
    "        return tf.nn.tanh(tanh_preactivation) * tf.nn.sigmoid(sigmoid_preactivation)\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        v = input_tensor[0]\n",
    "        h = input_tensor[1]\n",
    "\n",
    "        vertical_preactivation = self.vertical_conv(v)  # NxN\n",
    "\n",
    "        # Shifting feature map down to ensure causality\n",
    "        v_to_h = self.padding(vertical_preactivation)\n",
    "        v_to_h = self.cropping(v_to_h)\n",
    "        v_to_h = self.v_to_h_conv(v_to_h)  # 1x1\n",
    "\n",
    "        horizontal_preactivation = self.horizontal_conv(h)  # 1xN\n",
    "        \n",
    "        v_out = self._gate(vertical_preactivation)\n",
    "\n",
    "        horizontal_preactivation = horizontal_preactivation + v_to_h\n",
    "        h_activated = self._gate(horizontal_preactivation)\n",
    "        h_activated = self.horizontal_output(h_activated)\n",
    "\n",
    "        if self.mask_type == 'A':\n",
    "            h_out = h_activated\n",
    "        elif self.mask_type == 'B':\n",
    "            h_out = h + h_activated\n",
    "\n",
    "        return v_out, h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WB57YufrVxn2"
   },
   "outputs": [],
   "source": [
    "# Create Gated PixelCNN model\n",
    "inputs = keras.layers.Input(shape=(height, width, n_channel))\n",
    "v, h = GatedBlock(mask_type='A', filters=64, kernel_size=3)([inputs, inputs])\n",
    "\n",
    "for i in range(7):\n",
    "    v, h = GatedBlock(mask_type='B', filters=64, kernel_size=3)([v, h])\n",
    "\n",
    "x = keras.layers.Activation(activation='relu')(h)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=1, strides=1)(x)\n",
    "\n",
    "x = keras.layers.Activation(activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=q_levels, kernel_size=1, strides=1)(x)\n",
    "\n",
    "gated_pixelcnn = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LnzHUaqV77d"
   },
   "outputs": [],
   "source": [
    "# Prepare optimizer and loss function\n",
    "lr_decay = 0.999995\n",
    "learning_rate = 1e-3\n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "compute_loss = keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsAgEKVzLCJD"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch_x, batch_y):\n",
    "    with tf.GradientTape() as ae_tape:\n",
    "        logits = gated_pixelcnn(batch_x, training=True)\n",
    "\n",
    "        loss = compute_loss(tf.squeeze(tf.one_hot(batch_y, q_levels)), logits)\n",
    "\n",
    "    gradients = ae_tape.gradient(loss, gated_pixelcnn.trainable_variables)\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "    optimizer.apply_gradients(zip(gradients, gated_pixelcnn.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "NoEPrfwQNM-s",
    "outputId": "52dae9be-4f84-4b91-c5ba-e2369259478e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 205s 655ms/step - loss: 0.1192\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 107s 343ms/step - loss: 0.0913\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 108s 344ms/step - loss: 0.0872\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 107s 341ms/step - loss: 0.0854\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 107s 341ms/step - loss: 0.0843\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 105s 336ms/step - loss: 0.0835\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 108s 344ms/step - loss: 0.0830\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 107s 342ms/step - loss: 0.0824\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 104s 333ms/step - loss: 0.0820\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 106s 340ms/step - loss: 0.0816\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 105s 335ms/step - loss: 0.0814\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 105s 336ms/step - loss: 0.0810\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 105s 336ms/step - loss: 0.0808\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 106s 337ms/step - loss: 0.0806\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 107s 340ms/step - loss: 0.0803\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 106s 338ms/step - loss: 0.0802\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 104s 332ms/step - loss: 0.0800\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0798\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 104s 333ms/step - loss: 0.0796\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 106s 338ms/step - loss: 0.0795\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 103s 330ms/step - loss: 0.0793\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0792\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0791\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 103s 330ms/step - loss: 0.0789\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0788\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 103s 330ms/step - loss: 0.0787\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0786\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0784\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 103s 329ms/step - loss: 0.0783\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0782\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0781\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 103s 329ms/step - loss: 0.0780\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0779\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0778\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 105s 335ms/step - loss: 0.0776\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 106s 339ms/step - loss: 0.0775\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 106s 340ms/step - loss: 0.0774\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 107s 342ms/step - loss: 0.0773\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 107s 342ms/step - loss: 0.0772\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 107s 342ms/step - loss: 0.0771\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 106s 338ms/step - loss: 0.0770\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 105s 337ms/step - loss: 0.0769\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 104s 331ms/step - loss: 0.0768\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0767\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0766\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0765\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 103s 329ms/step - loss: 0.0764\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0763\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0762\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 103s 328ms/step - loss: 0.0761\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_epochs = 50\n",
    "n_iter = int(np.ceil(x_train_quantised.shape[0] / batch_size))\n",
    "for epoch in range(n_epochs):\n",
    "    progbar = Progbar(n_iter)\n",
    "    print('Epoch {:}/{:}'.format(epoch + 1, n_epochs))\n",
    "\n",
    "    for i_iter, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "        optimizer.lr = optimizer.lr * lr_decay\n",
    "        loss = train_step(batch_x, batch_y)\n",
    "\n",
    "        progbar.add(1, values=[('loss', loss)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ue0vZbitSNmz",
    "outputId": "b4be6fad-6f16-4380-8dbd-2e01bc3e1af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll : 0.08091852068901062 nats\n",
      "bits/dim : 0.11674074851410661\n"
     ]
    }
   ],
   "source": [
    "# Test set performance\n",
    "test_loss = []\n",
    "for batch_x, batch_y in test_dataset:\n",
    "    logits = gated_pixelcnn(batch_x, training=False)\n",
    "\n",
    "    # Calculate cross-entropy (= negative log-likelihood)\n",
    "    loss = compute_loss(tf.one_hot(batch_y, q_levels), logits)\n",
    "\n",
    "    test_loss.append(loss)\n",
    "print('nll : {:} nats'.format(np.array(test_loss).mean()))\n",
    "print('bits/dim : {:}'.format(np.array(test_loss).mean() / np.log(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "-Ia9VXYySkuW",
    "outputId": "924010f4-0dcb-4a82-bd1d-75c6091cadc6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating new images\n",
    "samples = np.zeros((100, height, width, n_channel), dtype='float32')\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        logits = gated_pixelcnn(samples)\n",
    "        next_sample = tf.random.categorical(logits[:, i, j, :], 1)\n",
    "        samples[:, i, j, 0] = (next_sample.numpy() / (q_levels - 1))[:, 0]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(100):\n",
    "    ax = fig.add_subplot(10, 10, i + 1)\n",
    "    ax.matshow(samples[i, :, :, 0], cmap=matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "KBuWx-FtSouR",
    "outputId": "85fb1988-aeea-4695-f5e3-d5a57d28bed6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAABECAYAAABu1lQcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAADy0lEQVR4nO3cQVLkOBAF0PTEHIFeTx2C+58A7kCvhztoFkwHBOFy2WW7UCrfW3Y4OpSWbL5Shqm1FgAAVfz10wMAAHgk4QcAKEX4AQBKEX4AgFKEHwCgFOEHAChF+AEAShF+AIBShB8AoJS/t1z89PTULpfLSUM519vbW7y/v09L12SuLyLi9fX1vbX2a+mazDWumcMINfbOs/ghc43W6afRa8xcX8T1Z3FT+LlcLvHy8nLcqB7o+fn55jWZ64uImKbp961rMte4Zg4j1Ng7z+KHzDVap59GrzFzfRHXn0XHXgBAKcIPAFDKpmMvtpum+ePU1tqDRwIAROj8AADF6Pwc5FqH59b1FTpAo9Q6N8fZawLGNE2T99MCnR8AoBSdnwNs7fpAT0bpzO2V8T58f/dkGjvb3XvC8If18Un4OcnSIvu6IDO+cNcaKRSOVMtRvt6TzOv3+9xmeCbPWI9Z5jPLOPfyzjmXYy8AoJRTOz8VPxDdWt/o9yO7W7uvDF2Ca/buLFtrdqc/4Oj3apajEWttbI/OCzo/AEApp3R+lhL6kem9lx3K2nFU3bn0Mk9b+LCwhuzd6UxjvdeanydZ78O9489a7x9r369L1+29B6eEn7Uf++6VfeGPLGvQO2rcPf+NjaOCWtY5zuqMD317/nh4y/rq+Xm75lZ92epZ0uO7wrEXAFDKw3/VfW+a7Xmnck321jrzvs5hjzubORmfnzNkma+IXGP9SVlOAqrM59o65+br+1zO/V97u306PwBAKf7I4cmqpPwR7NmpzO1QsuxEtxp1TY82T3Myd6GXOgRz/9ZbXZnv/dHu+cD76PeOzg8AUEqazk+2bxXO/BW9nmWbp7XW1tJrB+iseRlpjjPZ8ht72Tt1o66xUes6osO19K3PUboPP9kf3K9GXewjM2efRnoWM1nzg+Deuel1ffe2edjLs/Ohp7/z59gLACil+85P1rSfddx7Za575OOgI8bTW017ZKwl45jvtfWYuXdZxnmEpVp7ug86PwBAKcIPAFCK8AMAlCL8AAClCD8AQCnCDwBQivADAJQi/AAApQg/AEApwg8AUIrwAwCUIvwAAKUIPwBAKcIPAFCK8AMAlCL8AAClCD8AQCnCDwBQivADAJQi/AAApQg/AEApwg8AUIrwAwCUMrXW1l88Tf9GxO/zhnOqf1prv5YuSF5fxPg13qwvQo0JjL5OI8av0Tr93+g1Jq8v4kqNm8IPAEB2jr0AgFKEHwCgFOEHAChF+AEAShF+AIBShB8AoBThBwAoRfgBAEoRfgCAUv4Dzge+SeXbn58AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAABECAYAAABu1lQcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAFDUlEQVR4nO3dQXLbOBAAQHArT3DOq0f4/y+w/+Cc4z9wD16XXCqKAkVCwmC6jylFhRFAeDAAyWme5wIAkMU/z24AAMAjSX4AgFQkPwBAKpIfACAVyQ8AkIrkBwBIRfIDAKQi+QEAUpH8AACp/Nry4ZeXl/l0OjVqSlsfHx/l8/NzWvtM5PhKKeX9/f1znuffa5+JHGNNH5Yixt65Fr9EjtE4PRs9xsjxlXL9WtyU/JxOp/L29nZcqx7o9fX15mcix1dKKdM0/bn1mcgx1vRhKWLsnWvxS+QYjdOz0WOMHF8p169F214AQCqSHwAglU3bXmw3TcvbqfM8P7glAEApKj8AQDIqPwe5VuG59fkMFaBRYl3q4+gxAWOapsn8tELlBwBIReXnAFurPtCTUSpze0X8HS7nnkhtZ7t7dxi+GR9nkp9G1gbZzwEZccKtNVJSOFIsR/n5m0Qev5d9G+GabDEeo/RnlHbuZc5py7YXAJBK08pPxgOiW+Mb/feI7tbqK0KV4Jq9K8t5nq1On+DoeTXK1oixNrZH5wsqPwBAKk0qP2sZ+pHZey8rlNp2ZF259NJPWzhYmEP06nSktt6r5u9J1N/h3vZHjfdb7fy69rm9v0GT5Kf2sO9e0Qf+yKImeke1u+dnbByVqEXt46haHPTt+fDwlvHV8/V2za34osWzpse5wrYXAJDKw29135vN9rxSuSZ6aZ1lP/uwx5XNkojXTwtR+quUWG19pig7AVn6szbOpf667Mul79pb7VP5AQBS8ZDDxrJk+SPYs1JZWqFEWYluNeqYHq2flkSuQq9VCJb+rbe4Iv/2R7vngPfR847KDwCQSpjKT7SzCi1v0etZtH6qVRtLrxWgVv0yUh9HsuWOveiVulHH2KhxHVHhWjvrc5Tuk5/oF+5Pow72kemzs5GuxUhq/hDc2ze9ju/eFg97uXa+9PScP9teAEAq3Vd+LkXO/rPr/cBfT21pKfPTqCOvwGsP/K79v8jxE1dPFZ9vKj8AQCrdVn5GWp1GbvseVpkxrFXkMhzcjxzHvW3vPealW5tHOPuTQYvDyi36vNvkJyp/8G8zeT3e1ruBMiQ9mYw0L0WMpcVzanp35HZri3e32fYCAFLpsvIT+Vkxj3g+QTQ99mGrMdb7oe4ltVWh3uO4xTUZqw9Hn0sjvon+XjVxPrqfVX4AgFS6rPyMIEtGf2n01do12eIljmxjs9e5N+vc2CuVHwAglS4rP71m7oxpzy20o94VNdJZn2/Z7rgZpQ8v236tDyPG6Pb95+ky+SG+3i/mteeI7P1e+mXrIb7o11ivLz9+lmddi7a9AIBUVH5I68gqwCgrtpGerM5Z5soCz3HrSMCWebfFuFX5AQBSUfkhvSwP+bsl6zmYrW9Gj+JnZTNi+0c36vvLaq6nHuYayQ+siDwJ7TF63F7cCsepvQPv3qTHu70AAHZS+QHSUhXhmY666eJZ7xTcWjnt6VETKj8AQCoqP1TZmqkvZf0R33ieib4A9qqd+7d+x9FUfgCAVFR+2KzmBH9tpj/CrZ0Az9BjNb2H8zw1JD+sqnnOzREvBPUsEoBYIj8l37YXAJDKtCXbmqbpbynlT7vmNPXvPM+/1z4QPL5Sxo/xZnyliDGA0cdpKePHaJz+b/QYg8dXypUYNyU/AADR2fYCAFKR/AAAqUh+AIBUJD8AQCqSHwAgFckPAJCK5AcASEXyAwCkIvkBAFL5D4QYq3XSuptvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filling occluded images\n",
    "occlude_start_row = 14\n",
    "num_generated_images = 10\n",
    "samples = np.copy(x_test_quantised[0:num_generated_images, :, :, :])\n",
    "samples = samples / (q_levels - 1)\n",
    "samples[:, occlude_start_row:, :, :] = 0\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(1, 10, i + 1)\n",
    "    ax.matshow(samples[i, :, :, 0], cmap=matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "\n",
    "for i in range(occlude_start_row, height):\n",
    "    for j in range(width):\n",
    "        logits = gated_pixelcnn(samples)\n",
    "        next_sample = tf.random.categorical(logits[:, i, j, :], 1)\n",
    "        samples[:, i, j, 0] = (next_sample.numpy() / (q_levels - 1))[:, 0]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(1, 10, i + 1)\n",
    "    ax.matshow(samples[i, :, :, 0], cmap=matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "gated_pixelcnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
