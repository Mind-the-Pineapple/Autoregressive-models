{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sh8yUGDPNSfo"
   },
   "outputs": [],
   "source": [
    "import random as rn\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lu1pR95h3tw1"
   },
   "outputs": [],
   "source": [
    "class MaskedConv2D(tf.keras.layers.Layer):\n",
    "    \"\"\"Convolutional layers with masks for autoregressive models\n",
    "\n",
    "    Convolutional layers with simple implementation to have masks type A and B.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 mask_type,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 input_n_channels=3):\n",
    "        super(MaskedConv2D, self).__init__()\n",
    "\n",
    "        assert mask_type in {'A', 'B'}\n",
    "        self.mask_type = mask_type\n",
    "\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding.upper()\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
    "        self.input_n_channels = input_n_channels\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=(self.kernel_size,\n",
    "                                             self.kernel_size,\n",
    "                                             int(input_shape[-1]),\n",
    "                                             self.filters),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      trainable=True)\n",
    "\n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                    shape=(self.filters,),\n",
    "                                    initializer=self.bias_initializer,\n",
    "                                    trainable=True)\n",
    "\n",
    "        center = self.kernel_size // 2\n",
    "\n",
    "        mask = np.ones(self.kernel.shape, dtype=np.float32)\n",
    "        mask[center, center + 1:, :, :] = 0.\n",
    "        mask[center + 1:, :, :, :] = 0.\n",
    "\n",
    "        for i in range(self.input_n_channels):\n",
    "            for j in range(self.input_n_channels):\n",
    "                if (self.mask_type == 'A' and i >= j) or (self.mask_type == 'B' and i > j):\n",
    "                    mask[center, center, i::self.input_n_channels, j::self.input_n_channels] = 0.\n",
    "\n",
    "        self.mask = tf.constant(mask, dtype=tf.float32, name='mask')\n",
    "\n",
    "    def call(self, input):\n",
    "        masked_kernel = tf.math.multiply(self.mask, self.kernel)\n",
    "        x = tf.nn.conv2d(input, masked_kernel, strides=[1, self.strides, self.strides, 1], padding=self.padding)\n",
    "        x = tf.nn.bias_add(x, self.bias)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kCIvwG5OiRh"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.Model):\n",
    "    \"\"\"Residual blocks that compose pixelCNN\n",
    "\n",
    "    Blocks of layers with 3 convolutional layers and one residual connection.\n",
    "    Based on Figure 5 from [1] where h indicates number of filters.\n",
    "\n",
    "    Refs:\n",
    "    [1] - Oord, A. V. D., Kalchbrenner, N., & Kavukcuoglu, K. (2016). Pixel\n",
    "     recurrent neural networks. arXiv preprint arXiv:1601.06759.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h):\n",
    "        super(ResidualBlock, self).__init__(name='')\n",
    "\n",
    "        self.conv2a = keras.layers.Conv2D(filters=h, kernel_size=1, strides=1)\n",
    "        self.conv2b = MaskedConv2D(mask_type='B', filters=h, kernel_size=3, strides=1)\n",
    "        self.conv2c = keras.layers.Conv2D(filters=2 * h, kernel_size=1, strides=1)\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        x = tf.nn.relu(input_tensor)\n",
    "        x = self.conv2a(x)\n",
    "\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2c(x)\n",
    "\n",
    "        x += input_tensor\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY4vPLROOufz"
   },
   "outputs": [],
   "source": [
    "def quantise(images, q_levels):\n",
    "    \"\"\"Quantise image into q levels\"\"\"\n",
    "    return (np.digitize(images, np.arange(q_levels) / q_levels) - 1).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdCWLDarT9Tg"
   },
   "outputs": [],
   "source": [
    "# Defining random seeds\n",
    "random_seed = 42\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "rn.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtfnOXuzUu3M"
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "height = 32\n",
    "width = 32\n",
    "n_channel = 3\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], height, width, n_channel)\n",
    "x_test = x_test.reshape(x_test.shape[0], height, width, n_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1577886498749,
     "user": {
      "displayName": "Walter Hugo Lopez Pinaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBjknD3RW8ZviowNPM9JlH9IWQElg2Arp9PS-Ba-A=s64",
      "userId": "09128201096829503895"
     },
     "user_tz": 0
    },
    "id": "6zZCb10GW5dW",
    "outputId": "6fc9f192-bc44-45a0-d4be-1f5aa3846c6b"
   },
   "outputs": [],
   "source": [
    "# Quantise the input data in q levels\n",
    "q_levels = 128\n",
    "x_train_quantised = quantise(x_train, q_levels)\n",
    "x_test_quantised = quantise(x_test, q_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2863,
     "status": "ok",
     "timestamp": 1577883141858,
     "user": {
      "displayName": "Walter Hugo Lopez Pinaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBjknD3RW8ZviowNPM9JlH9IWQElg2Arp9PS-Ba-A=s64",
      "userId": "09128201096829503895"
     },
     "user_tz": 0
    },
    "id": "qSNKy9noDr2Y",
    "outputId": "04dc7d68-ba4f-490f-db0d-6e6081abb23b"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_buf = 20000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_quantised / (q_levels - 1),\n",
    "                                                    x_train_quantised.astype('int32')))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_quantised / (q_levels - 1),\n",
    "                                                   x_test_quantised.astype('int32')))\n",
    "test_dataset = test_dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q9eV2XzQ93g"
   },
   "outputs": [],
   "source": [
    "# Create PixelCNN model\n",
    "inputs = keras.layers.Input(shape=(height, width, n_channel))\n",
    "x = MaskedConv2D(mask_type='A', filters=128, kernel_size=7, strides=1)(inputs)\n",
    "\n",
    "for i in range(15):\n",
    "    x = ResidualBlock(h=64)(x)\n",
    "\n",
    "x = keras.layers.Activation(activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=1, strides=1)(x)\n",
    "x = keras.layers.Activation(activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=1, strides=1)(x)\n",
    "x = keras.layers.Conv2D(filters=n_channel * q_levels, kernel_size=1, strides=1)(x)  # shape [N,H,W,DC]\n",
    "\n",
    "pixelcnn = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNMRKtvzRBw0"
   },
   "outputs": [],
   "source": [
    "# Prepare optimizer and loss function\n",
    "lr_decay = 0.99995\n",
    "learning_rate = 1e-2\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "compute_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1577886521175,
     "user": {
      "displayName": "Walter Hugo Lopez Pinaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBjknD3RW8ZviowNPM9JlH9IWQElg2Arp9PS-Ba-A=s64",
      "userId": "09128201096829503895"
     },
     "user_tz": 0
    },
    "id": "1QbqYMhjJZQQ",
    "outputId": "d57da819-b478-40db-a3f2-a4dae6f11482"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch_x, batch_y):\n",
    "    with tf.GradientTape() as ae_tape:\n",
    "        logits = pixelcnn(batch_x, training=True)\n",
    "\n",
    "        logits = tf.reshape(logits, [-1, height, width, q_levels, n_channel])  # shape [N,H,W,DC] -> [N,H,W,D,C]\n",
    "        logits = tf.transpose(logits, perm=[0, 1, 2, 4, 3])  # shape [N,H,W,D,C] -> [N,H,W,C,D]\n",
    "\n",
    "        loss = compute_loss(tf.one_hot(batch_y, q_levels), logits)\n",
    "\n",
    "    gradients = ae_tape.gradient(loss, pixelcnn.trainable_variables)\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "    optimizer.apply_gradients(zip(gradients, pixelcnn.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RnvCgyDLRHPk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "196/196 [==============================] - 92s 467ms/step - loss: 3.8075\n",
      "Epoch 2/500\n",
      "105/196 [===============>..............] - ETA: 37s - loss: 3.1941"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_epochs = 500\n",
    "n_iter = int(np.ceil(x_train_quantised.shape[0] / batch_size))\n",
    "for epoch in range(n_epochs):\n",
    "    progbar = Progbar(n_iter)\n",
    "    print('Epoch {:}/{:}'.format(epoch + 1, n_epochs))\n",
    "\n",
    "    for i_iter, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "        start = time.time()\n",
    "        optimizer.lr = optimizer.lr * lr_decay\n",
    "        loss = train_step(batch_x, batch_y)\n",
    "\n",
    "        progbar.add(1, values=[(\"loss\", loss)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qiAWABHGRS6i"
   },
   "outputs": [],
   "source": [
    "# Generating new images\n",
    "samples = np.zeros((10, height, width, n_channel)) + 0.5 * np.random.rand(10, height, width, n_channel)\n",
    "\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        for k in range(n_channel):\n",
    "            logits = pixelcnn(samples)\n",
    "            logits = tf.reshape(logits, [-1, height, width, q_levels, n_channel])\n",
    "            logits = tf.transpose(logits, perm=[0, 1, 2, 4, 3])\n",
    "            next_sample = tf.random.categorical(logits[:, i, j, k, :], 1)\n",
    "            samples[:, i, j, k] = (next_sample.numpy() / (q_levels - 1))[:, 0]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(samples[i, :, :, :])\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuF2Dpg8TU32"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Generating new images\n",
    "occlude_start_row = 14\n",
    "num_generated_images = 1\n",
    "samples = np.copy(x_train_quantised[:10, :, :, :])\n",
    "samples = samples / (q_levels - 1)\n",
    "samples[:, occlude_start_row:, :, :] = 0\n",
    "\n",
    "for i in range(occlude_start_row, height):\n",
    "    for j in range(width):\n",
    "        for k in range(n_channel):\n",
    "            logits = pixelcnn(samples)\n",
    "            logits = tf.reshape(logits, [-1, height, width, q_levels, n_channel])\n",
    "            logits = tf.transpose(logits, perm=[0, 1, 2, 4, 3])\n",
    "            next_sample = tf.random.categorical(logits[:, i, j, k, :], 1)\n",
    "            samples[:, i, j, k] = (next_sample.numpy() / (q_levels - 1))[:, 0]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(samples[i, :, :, :])\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "modelling_coloured_images.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
