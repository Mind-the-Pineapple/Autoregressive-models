{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multichannel_cifar10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpSh3dRh_JKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "15c7a091-7cf9-4d08-e095-0e01a950b690"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 85kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow-gpu==2.0.0-rc1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow-gpu==2.0.0-rc1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.0.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.16.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.33.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (41.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgXBspaF_rDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as rn\n",
        "import time\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWRqRdt5AIyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskedConv2D(tf.keras.layers.Layer):\n",
        "    \"\"\"Convolutional layers with masks for autoregressive models\n",
        "\n",
        "    Convolutional layers with simple implementation to have masks type A and B.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 mask_type,\n",
        "                 filters,\n",
        "                 kernel_size,\n",
        "                 strides=1,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros'):\n",
        "        super(MaskedConv2D, self).__init__()\n",
        "\n",
        "        assert mask_type in {'A', 'B'}\n",
        "        self.mask_type = mask_type\n",
        "\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding.upper()\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\"kernel\",\n",
        "                                      shape=(self.kernel_size,\n",
        "                                             self.kernel_size,\n",
        "                                             int(input_shape[-1]),\n",
        "                                             self.filters),\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      trainable=True)\n",
        "\n",
        "        self.bias = self.add_weight(\"bias\",\n",
        "                                    shape=(self.filters,),\n",
        "                                    initializer=self.bias_initializer,\n",
        "                                    trainable=True)\n",
        "\n",
        "        mask = np.ones(self.kernel.shape, dtype=np.float32)\n",
        "        mask[self.kernel_size // 2, self.kernel_size // 2 + (self.mask_type == 'B'):, :, :] = 0.\n",
        "        mask[self.kernel_size // 2 + 1:, :, :] = 0.\n",
        "\n",
        "        self.mask = tf.constant(mask,\n",
        "                                dtype=tf.float32,\n",
        "                                name='mask')\n",
        "\n",
        "    def call(self, input):\n",
        "        masked_kernel = tf.math.multiply(self.mask, self.kernel)\n",
        "        x = tf.nn.conv2d(input, masked_kernel, strides=[1, self.strides, self.strides, 1], padding=self.padding)\n",
        "        x = tf.nn.bias_add(x, self.bias)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_ljhq0FALQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(tf.keras.Model):\n",
        "    \"\"\"Residual blocks that compose pixelCNN\n",
        "\n",
        "    Blocks of layers with 3 convolutional layers and one residual connection.\n",
        "    Based on Figure 5 from [1] where h indicates number of filters.\n",
        "\n",
        "    Refs:\n",
        "    [1] - Oord, A. V. D., Kalchbrenner, N., & Kavukcuoglu, K. (2016). Pixel\n",
        "     recurrent neural networks. arXiv preprint arXiv:1601.06759.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, h):\n",
        "        super(ResidualBlock, self).__init__(name='')\n",
        "\n",
        "        self.conv2a = keras.layers.Conv2D(filters=h, kernel_size=1, strides=1)\n",
        "        self.conv2b = MaskedConv2D(mask_type='B', filters=h, kernel_size=3, strides=1)\n",
        "        self.conv2c = keras.layers.Conv2D(filters=2 * h, kernel_size=1, strides=1)\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = tf.nn.relu(input_tensor)\n",
        "        x = self.conv2a(x)\n",
        "\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2b(x)\n",
        "\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2c(x)\n",
        "\n",
        "        x += input_tensor\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drtl9dwsAQMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quantisize(images, q_levels):\n",
        "    \"\"\"Digitize image into q levels\"\"\"\n",
        "    return (np.digitize(images, np.arange(q_levels) / q_levels) - 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sigAYcAfATkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_from(distribution):\n",
        "    \"\"\"\"\"\"\n",
        "    batch_size, bins = distribution.shape\n",
        "    return np.array([np.random.choice(bins, p=distr) for distr in distribution])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7th6eFNAZfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Defining random seeds\n",
        "random_seed = 42\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "rn.seed(random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACyt8q_pAep_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "31f01648-7605-4e16-c109-79efbdfe3241"
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Loading data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "height = 32\n",
        "width = 32\n",
        "n_channel = 3\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], height, width, n_channel)\n",
        "x_test = x_test.reshape(x_test.shape[0], height, width, n_channel)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrgFLyZ7AhuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Quantisize the input data in q levels\n",
        "q_levels = 256\n",
        "x_train_quantised = quantisize(x_train, q_levels)\n",
        "x_test_quantised = quantisize(x_test, q_levels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNa7rI0nAkzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "0ca8e091-e049-43d1-9dee-0cdb92459609"
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Creating input stream using tf.data API\n",
        "batch_size = 128\n",
        "train_buf = 60000\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_quantised / (q_levels - 1),\n",
        "                                                    x_train_quantised.astype('int32')))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_quantised / (q_levels - 1),\n",
        "                                                   x_test_quantised.astype('int32')))\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHpl6p45AtGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Create PixelCNN model\n",
        "inputs = keras.layers.Input(shape=(height, width, n_channel))\n",
        "x = MaskedConv2D(mask_type='A', filters=128, kernel_size=7, strides=1)(inputs)\n",
        "\n",
        "for i in range(15):\n",
        "    x = ResidualBlock(h=64)(x)\n",
        "\n",
        "x = keras.layers.Activation(activation='relu')(x)\n",
        "x = keras.layers.Conv2D(filters=128, kernel_size=1, strides=1)(x)\n",
        "x = keras.layers.Activation(activation='relu')(x)\n",
        "x = keras.layers.Conv2D(filters=n_channel * q_levels, kernel_size=1, strides=1)(x)  # shape [N,H,W,DC]\n",
        "\n",
        "pixelcnn = tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK0rhyk8A1si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Prepare optimizer and loss function\n",
        "lr_decay = 0.9995\n",
        "learning_rate = 1e-3\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "compute_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn2RvQ3tA3j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "@tf.function\n",
        "def train_step(batch_x, batch_y):\n",
        "    with tf.GradientTape() as ae_tape:\n",
        "        logits = pixelcnn(batch_x, training=True)\n",
        "\n",
        "        logits = tf.reshape(logits, [-1, height, width, q_levels, n_channel])  # shape [N,H,W,DC] -> [N,H,W,D,C]\n",
        "        logits = tf.transpose(logits, perm=[0, 1, 2, 4, 3])  # shape [N,H,W,D,C] -> [N,H,W,C,D]\n",
        "\n",
        "        loss = compute_loss(tf.one_hot(batch_y, q_levels), logits)\n",
        "\n",
        "    gradients = ae_tape.gradient(loss, pixelcnn.trainable_variables)\n",
        "    gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
        "    optimizer.apply_gradients(zip(gradients, pixelcnn.trainable_variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbIowQotA91c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22bdba94-6f61-4284-fba1-8e6b62d52f17"
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Training loop\n",
        "n_epochs = 30\n",
        "n_iter = int(np.ceil(x_train_quantised.shape[0] / batch_size))\n",
        "for epoch in range(n_epochs):\n",
        "    start_epoch = time.time()\n",
        "    for i_iter, (batch_x, batch_y) in enumerate(train_dataset):\n",
        "        start = time.time()\n",
        "        optimizer.lr = optimizer.lr * lr_decay\n",
        "        loss = train_step(batch_x, batch_y)\n",
        "        iter_time = time.time() - start\n",
        "        if i_iter % 100 == 0:\n",
        "            print('EPOCH {:3d}: ITER {:4d}/{:4d} TIME: {:.2f} LOSS: {:.4f}'.format(epoch,\n",
        "                                                                                   i_iter, n_iter,\n",
        "                                                                                   iter_time,\n",
        "                                                                                   loss))\n",
        "    epoch_time = time.time() - start_epoch\n",
        "    print('EPOCH {:3d}: TIME: {:.2f} ETA: {:.2f}'.format(epoch,\n",
        "                                                         epoch_time,\n",
        "                                                         epoch_time * (n_epochs - epoch)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH   0: ITER    0/ 391 TIME: 7.97 LOSS: 5.5448\n",
            "EPOCH   0: ITER  100/ 391 TIME: 0.75 LOSS: 4.7196\n",
            "EPOCH   0: ITER  200/ 391 TIME: 0.74 LOSS: 4.3667\n",
            "EPOCH   0: ITER  300/ 391 TIME: 0.75 LOSS: 4.3091\n",
            "EPOCH   0: TIME: 302.30 ETA: 9069.01\n",
            "EPOCH   1: ITER    0/ 391 TIME: 0.03 LOSS: 4.1031\n",
            "EPOCH   1: ITER  100/ 391 TIME: 0.72 LOSS: 4.0511\n",
            "EPOCH   1: ITER  200/ 391 TIME: 0.73 LOSS: 4.0636\n",
            "EPOCH   1: ITER  300/ 391 TIME: 0.72 LOSS: 3.8890\n",
            "EPOCH   1: TIME: 294.29 ETA: 8534.48\n",
            "EPOCH   2: ITER    0/ 391 TIME: 0.03 LOSS: 3.9047\n",
            "EPOCH   2: ITER  100/ 391 TIME: 0.73 LOSS: 4.0079\n",
            "EPOCH   2: ITER  200/ 391 TIME: 0.75 LOSS: 3.8334\n",
            "EPOCH   2: ITER  300/ 391 TIME: 0.67 LOSS: 3.9694\n",
            "EPOCH   2: TIME: 293.90 ETA: 8229.14\n",
            "EPOCH   3: ITER    0/ 391 TIME: 0.04 LOSS: 3.7701\n",
            "EPOCH   3: ITER  100/ 391 TIME: 0.74 LOSS: 3.8000\n",
            "EPOCH   3: ITER  200/ 391 TIME: 0.73 LOSS: 3.7300\n",
            "EPOCH   3: ITER  300/ 391 TIME: 0.72 LOSS: 3.8863\n",
            "EPOCH   3: TIME: 294.10 ETA: 7940.66\n",
            "EPOCH   4: ITER    0/ 391 TIME: 0.03 LOSS: 3.7345\n",
            "EPOCH   4: ITER  100/ 391 TIME: 0.74 LOSS: 3.7173\n",
            "EPOCH   4: ITER  200/ 391 TIME: 0.73 LOSS: 3.7867\n",
            "EPOCH   4: ITER  300/ 391 TIME: 0.74 LOSS: 3.6576\n",
            "EPOCH   4: TIME: 292.86 ETA: 7614.29\n",
            "EPOCH   5: ITER    0/ 391 TIME: 0.03 LOSS: 3.6652\n",
            "EPOCH   5: ITER  100/ 391 TIME: 0.73 LOSS: 3.6437\n",
            "EPOCH   5: ITER  200/ 391 TIME: 0.73 LOSS: 3.6377\n",
            "EPOCH   5: ITER  300/ 391 TIME: 0.75 LOSS: 3.6345\n",
            "EPOCH   5: TIME: 292.78 ETA: 7319.61\n",
            "EPOCH   6: ITER    0/ 391 TIME: 0.03 LOSS: 3.6468\n",
            "EPOCH   6: ITER  100/ 391 TIME: 0.73 LOSS: 3.5990\n",
            "EPOCH   6: ITER  200/ 391 TIME: 0.73 LOSS: 3.6484\n",
            "EPOCH   6: ITER  300/ 391 TIME: 0.73 LOSS: 3.5816\n",
            "EPOCH   6: TIME: 292.79 ETA: 7027.01\n",
            "EPOCH   7: ITER    0/ 391 TIME: 0.03 LOSS: 3.5786\n",
            "EPOCH   7: ITER  100/ 391 TIME: 0.72 LOSS: 3.5501\n",
            "EPOCH   7: ITER  200/ 391 TIME: 0.73 LOSS: 3.5629\n",
            "EPOCH   7: ITER  300/ 391 TIME: 0.73 LOSS: 3.5297\n",
            "EPOCH   7: TIME: 292.66 ETA: 6731.24\n",
            "EPOCH   8: ITER    0/ 391 TIME: 0.03 LOSS: 3.5296\n",
            "EPOCH   8: ITER  100/ 391 TIME: 0.73 LOSS: 3.5459\n",
            "EPOCH   8: ITER  200/ 391 TIME: 0.73 LOSS: 3.4962\n",
            "EPOCH   8: ITER  300/ 391 TIME: 0.73 LOSS: 3.5934\n",
            "EPOCH   8: TIME: 292.78 ETA: 6441.19\n",
            "EPOCH   9: ITER    0/ 391 TIME: 0.03 LOSS: 3.5739\n",
            "EPOCH   9: ITER  100/ 391 TIME: 0.73 LOSS: 3.5132\n",
            "EPOCH   9: ITER  200/ 391 TIME: 0.73 LOSS: 3.5155\n",
            "EPOCH   9: ITER  300/ 391 TIME: 0.73 LOSS: 3.5638\n",
            "EPOCH   9: TIME: 292.63 ETA: 6145.19\n",
            "EPOCH  10: ITER    0/ 391 TIME: 0.04 LOSS: 3.5785\n",
            "EPOCH  10: ITER  100/ 391 TIME: 0.73 LOSS: 3.5212\n",
            "EPOCH  10: ITER  200/ 391 TIME: 0.77 LOSS: 3.4778\n",
            "EPOCH  10: ITER  300/ 391 TIME: 0.73 LOSS: 3.5032\n",
            "EPOCH  10: TIME: 292.48 ETA: 5849.56\n",
            "EPOCH  11: ITER    0/ 391 TIME: 0.03 LOSS: 3.4702\n",
            "EPOCH  11: ITER  100/ 391 TIME: 0.73 LOSS: 3.4723\n",
            "EPOCH  11: ITER  200/ 391 TIME: 0.73 LOSS: 3.4472\n",
            "EPOCH  11: ITER  300/ 391 TIME: 0.73 LOSS: 3.5553\n",
            "EPOCH  11: TIME: 292.49 ETA: 5557.23\n",
            "EPOCH  12: ITER    0/ 391 TIME: 0.03 LOSS: 3.4569\n",
            "EPOCH  12: ITER  100/ 391 TIME: 0.74 LOSS: 3.4204\n",
            "EPOCH  12: ITER  200/ 391 TIME: 0.73 LOSS: 3.4529\n",
            "EPOCH  12: ITER  300/ 391 TIME: 0.73 LOSS: 3.4962\n",
            "EPOCH  12: TIME: 292.45 ETA: 5264.17\n",
            "EPOCH  13: ITER    0/ 391 TIME: 0.07 LOSS: 3.5430\n",
            "EPOCH  13: ITER  100/ 391 TIME: 0.73 LOSS: 3.5220\n",
            "EPOCH  13: ITER  200/ 391 TIME: 0.72 LOSS: 3.4593\n",
            "EPOCH  13: ITER  300/ 391 TIME: 0.73 LOSS: 3.4812\n",
            "EPOCH  13: TIME: 292.40 ETA: 4970.84\n",
            "EPOCH  14: ITER    0/ 391 TIME: 0.03 LOSS: 3.4659\n",
            "EPOCH  14: ITER  100/ 391 TIME: 0.73 LOSS: 3.5273\n",
            "EPOCH  14: ITER  200/ 391 TIME: 0.73 LOSS: 3.4591\n",
            "EPOCH  14: ITER  300/ 391 TIME: 0.73 LOSS: 3.4337\n",
            "EPOCH  14: TIME: 292.51 ETA: 4680.21\n",
            "EPOCH  15: ITER    0/ 391 TIME: 0.03 LOSS: 3.4438\n",
            "EPOCH  15: ITER  100/ 391 TIME: 0.74 LOSS: 3.4763\n",
            "EPOCH  15: ITER  200/ 391 TIME: 0.74 LOSS: 3.4320\n",
            "EPOCH  15: ITER  300/ 391 TIME: 0.73 LOSS: 3.4646\n",
            "EPOCH  15: TIME: 292.47 ETA: 4386.99\n",
            "EPOCH  16: ITER    0/ 391 TIME: 0.04 LOSS: 3.4743\n",
            "EPOCH  16: ITER  100/ 391 TIME: 0.76 LOSS: 3.4618\n",
            "EPOCH  16: ITER  200/ 391 TIME: 0.83 LOSS: 3.4725\n",
            "EPOCH  16: ITER  300/ 391 TIME: 0.73 LOSS: 3.3735\n",
            "EPOCH  16: TIME: 292.25 ETA: 4091.53\n",
            "EPOCH  17: ITER    0/ 391 TIME: 0.03 LOSS: 3.4849\n",
            "EPOCH  17: ITER  100/ 391 TIME: 0.73 LOSS: 3.4250\n",
            "EPOCH  17: ITER  200/ 391 TIME: 0.73 LOSS: 3.4655\n",
            "EPOCH  17: ITER  300/ 391 TIME: 0.73 LOSS: 3.4522\n",
            "EPOCH  17: TIME: 292.62 ETA: 3804.01\n",
            "EPOCH  18: ITER    0/ 391 TIME: 0.03 LOSS: 3.5033\n",
            "EPOCH  18: ITER  100/ 391 TIME: 0.74 LOSS: 3.3868\n",
            "EPOCH  18: ITER  200/ 391 TIME: 0.73 LOSS: 3.4648\n",
            "EPOCH  18: ITER  300/ 391 TIME: 0.73 LOSS: 3.4367\n",
            "EPOCH  18: TIME: 292.88 ETA: 3514.58\n",
            "EPOCH  19: ITER    0/ 391 TIME: 0.03 LOSS: 3.5045\n",
            "EPOCH  19: ITER  100/ 391 TIME: 0.74 LOSS: 3.4993\n",
            "EPOCH  19: ITER  200/ 391 TIME: 0.73 LOSS: 3.4899\n",
            "EPOCH  19: ITER  300/ 391 TIME: 0.74 LOSS: 3.4733\n",
            "EPOCH  19: TIME: 292.81 ETA: 3220.96\n",
            "EPOCH  20: ITER    0/ 391 TIME: 0.03 LOSS: 3.4624\n",
            "EPOCH  20: ITER  100/ 391 TIME: 0.73 LOSS: 3.4839\n",
            "EPOCH  20: ITER  200/ 391 TIME: 0.73 LOSS: 3.4499\n",
            "EPOCH  20: ITER  300/ 391 TIME: 0.73 LOSS: 3.4534\n",
            "EPOCH  20: TIME: 292.87 ETA: 2928.69\n",
            "EPOCH  21: ITER    0/ 391 TIME: 0.03 LOSS: 3.4658\n",
            "EPOCH  21: ITER  100/ 391 TIME: 0.73 LOSS: 3.4290\n",
            "EPOCH  21: ITER  200/ 391 TIME: 0.82 LOSS: 3.3651\n",
            "EPOCH  21: ITER  300/ 391 TIME: 0.74 LOSS: 3.4696\n",
            "EPOCH  21: TIME: 292.69 ETA: 2634.19\n",
            "EPOCH  22: ITER    0/ 391 TIME: 0.03 LOSS: 3.4658\n",
            "EPOCH  22: ITER  100/ 391 TIME: 0.73 LOSS: 3.4837\n",
            "EPOCH  22: ITER  200/ 391 TIME: 0.74 LOSS: 3.4718\n",
            "EPOCH  22: ITER  300/ 391 TIME: 0.73 LOSS: 3.4739\n",
            "EPOCH  22: TIME: 292.70 ETA: 2341.57\n",
            "EPOCH  23: ITER    0/ 391 TIME: 0.03 LOSS: 3.4928\n",
            "EPOCH  23: ITER  100/ 391 TIME: 0.73 LOSS: 3.4615\n",
            "EPOCH  23: ITER  200/ 391 TIME: 0.73 LOSS: 3.4523\n",
            "EPOCH  23: ITER  300/ 391 TIME: 0.72 LOSS: 3.5357\n",
            "EPOCH  23: TIME: 292.79 ETA: 2049.54\n",
            "EPOCH  24: ITER    0/ 391 TIME: 0.03 LOSS: 3.5408\n",
            "EPOCH  24: ITER  100/ 391 TIME: 0.73 LOSS: 3.4845\n",
            "EPOCH  24: ITER  200/ 391 TIME: 0.82 LOSS: 3.4312\n",
            "EPOCH  24: ITER  300/ 391 TIME: 0.74 LOSS: 3.4066\n",
            "EPOCH  24: TIME: 292.78 ETA: 1756.71\n",
            "EPOCH  25: ITER    0/ 391 TIME: 0.06 LOSS: 3.4449\n",
            "EPOCH  25: ITER  100/ 391 TIME: 0.74 LOSS: 3.4442\n",
            "EPOCH  25: ITER  200/ 391 TIME: 0.73 LOSS: 3.4231\n",
            "EPOCH  25: ITER  300/ 391 TIME: 0.73 LOSS: 3.4188\n",
            "EPOCH  25: TIME: 292.90 ETA: 1464.51\n",
            "EPOCH  26: ITER    0/ 391 TIME: 0.13 LOSS: 3.4709\n",
            "EPOCH  26: ITER  100/ 391 TIME: 0.74 LOSS: 3.4474\n",
            "EPOCH  26: ITER  200/ 391 TIME: 0.74 LOSS: 3.4744\n",
            "EPOCH  26: ITER  300/ 391 TIME: 0.73 LOSS: 3.4948\n",
            "EPOCH  26: TIME: 292.92 ETA: 1171.68\n",
            "EPOCH  27: ITER    0/ 391 TIME: 0.03 LOSS: 3.4806\n",
            "EPOCH  27: ITER  100/ 391 TIME: 0.73 LOSS: 3.4347\n",
            "EPOCH  27: ITER  200/ 391 TIME: 0.71 LOSS: 3.3765\n",
            "EPOCH  27: ITER  300/ 391 TIME: 0.73 LOSS: 3.4948\n",
            "EPOCH  27: TIME: 292.85 ETA: 878.54\n",
            "EPOCH  28: ITER    0/ 391 TIME: 0.04 LOSS: 3.4804\n",
            "EPOCH  28: ITER  100/ 391 TIME: 0.73 LOSS: 3.4538\n",
            "EPOCH  28: ITER  200/ 391 TIME: 0.83 LOSS: 3.4564\n",
            "EPOCH  28: ITER  300/ 391 TIME: 0.74 LOSS: 3.3778\n",
            "EPOCH  28: TIME: 292.90 ETA: 585.80\n",
            "EPOCH  29: ITER    0/ 391 TIME: 0.04 LOSS: 3.4636\n",
            "EPOCH  29: ITER  100/ 391 TIME: 0.74 LOSS: 3.4016\n",
            "EPOCH  29: ITER  200/ 391 TIME: 0.73 LOSS: 3.4695\n",
            "EPOCH  29: ITER  300/ 391 TIME: 0.74 LOSS: 3.3842\n",
            "EPOCH  29: TIME: 292.99 ETA: 292.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8EWJD75BDED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0ae9dfd9-3a1b-4de1-fd9b-d224bc88cfc6"
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Test\n",
        "test_loss = []\n",
        "for batch_x, batch_y in test_dataset:\n",
        "    logits = pixelcnn(batch_x, training=False)\n",
        "    logits = tf.reshape(logits, [-1, height, width, q_levels, n_channel])\n",
        "    logits = tf.transpose(logits, perm=[0, 1, 2, 4, 3])\n",
        "\n",
        "    # Calculate cross-entropy (= negative log-likelihood)\n",
        "    loss = compute_loss(tf.one_hot(batch_y, q_levels), logits)\n",
        "\n",
        "    test_loss.append(loss)\n",
        "print('nll : {:} nats'.format(np.array(test_loss).mean()))\n",
        "print('bits/dim : {:}'.format(np.array(test_loss).mean() / (height * width)))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nll : 3.438567638397217 nats\n",
            "bits/dim : 0.003357976209372282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deJgSHmOBGfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "# Generating new images\n",
        "samples = (np.random.rand(9, height, width, n_channel) * 0.01).astype('float32')\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        for k in range(n_channel):\n",
        "            logits = pixelcnn(samples)\n",
        "            logits = tf.reshape(logits, [-1, height, width, q_levels, n_channel])\n",
        "            logits = tf.transpose(logits, perm=[0, 1, 2, 4, 3])\n",
        "            probs = tf.nn.softmax(logits)\n",
        "\n",
        "            next_sample = probs[:, i, j, k, :]\n",
        "            samples[:, i, j, k] = sample_from(next_sample.numpy()) / (q_levels - 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKU5UfPiBM0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "6be8b2da-b173-4042-dc32-f9668b71e426"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "for x in range(1, 3):\n",
        "    for y in range(1, 3):\n",
        "        ax = fig.add_subplot(3, 3, 3 * y + x)\n",
        "        ax.imshow(samples[3 * y + x, :, :, :])\n",
        "        plt.xticks(np.array([]))\n",
        "        plt.yticks(np.array([]))\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAF1CAYAAADm9iFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhIg5/x8fI5jW0zko8gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}